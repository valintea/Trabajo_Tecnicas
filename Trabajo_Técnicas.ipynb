{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valintea/Trabajo_Tecnicas/blob/main/Trabajo_T%C3%A9cnicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('Tweets.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "ln8aZ2tB-5xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "52HGIsJjDQNi",
        "outputId": "31e74e44-e426-4dc6-9222-b1c8cb6d669a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
              "0  570306133677760513           neutral                        1.0000   \n",
              "1  570301130888122368          positive                        0.3486   \n",
              "2  570301083672813571           neutral                        0.6837   \n",
              "3  570301031407624196          negative                        1.0000   \n",
              "4  570300817074462722          negative                        1.0000   \n",
              "\n",
              "  negativereason  negativereason_confidence         airline  \\\n",
              "0            NaN                        NaN  Virgin America   \n",
              "1            NaN                     0.0000  Virgin America   \n",
              "2            NaN                        NaN  Virgin America   \n",
              "3     Bad Flight                     0.7033  Virgin America   \n",
              "4     Can't Tell                     1.0000  Virgin America   \n",
              "\n",
              "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
              "0                    NaN     cairdin                 NaN              0   \n",
              "1                    NaN    jnardino                 NaN              0   \n",
              "2                    NaN  yvonnalynn                 NaN              0   \n",
              "3                    NaN    jnardino                 NaN              0   \n",
              "4                    NaN    jnardino                 NaN              0   \n",
              "\n",
              "                                                text tweet_coord  \\\n",
              "0                @VirginAmerica What @dhepburn said.         NaN   \n",
              "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
              "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
              "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
              "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
              "\n",
              "               tweet_created tweet_location               user_timezone  \n",
              "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
              "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
              "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
              "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
              "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8478d37a-b2f9-4ae9-8774-787cd2dc483b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8478d37a-b2f9-4ae9-8774-787cd2dc483b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8478d37a-b2f9-4ae9-8774-787cd2dc483b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8478d37a-b2f9-4ae9-8774-787cd2dc483b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5e5705e1-764c-4f76-b649-52172fb935f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e5705e1-764c-4f76-b649-52172fb935f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5e5705e1-764c-4f76-b649-52172fb935f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in df['text'][90:120]:\n",
        "    print(tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPzcLYUXCP5Y",
        "outputId": "7ae2a3a1-3785-4eb7-e5af-a9f8ed73fae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@VirginAmerica \"You down with RNP?\" \"Yeah you know me!\"\n",
            "@VirginAmerica hi, i did not get points on my elevate account for my most recent flight, how do i add the flight and points to my account?\n",
            "@VirginAmerica I like the TV and interesting video . Just disappointed in Cancelled Flightled flight when other flights went out to jfk on Saturday .\n",
            "@VirginAmerica just landed in LAX, an hour after I should of been here. Your no Late Flight bag check is not business travel friendly #nomorevirgin\n",
            "@VirginAmerica why is flight 345 redirected?\n",
            "@VirginAmerica Is it me, or is your website down?  BTW, your new website isn't a great user experience.  Time for another redesign.\n",
            "@VirginAmerica I can't check in or add a bag. Your website isn't working. I've tried both desktop and mobile http://t.co/AvyqdMpi1Y\n",
            "@VirginAmerica - Let 2 scanned in passengers leave the plane than told someone to remove their bag from 1st class bin? #uncomfortable\n",
            "@virginamerica What is your phone number. I can't find who to call about a flight reservation.\n",
            "@VirginAmerica is anyone doing anything there today?  Website is useless and no one is answering the phone.\n",
            "@VirginAmerica trying to add my boy Prince to my ressie. SF this Thursday @VirginAmerica from LAX http://t.co/GsB2J3c4gM\n",
            "@VirginAmerica why must a traveler miss a flight to Late Flight check a bag?  I missed my morning appointments and you lost my business. #sfo2lax\n",
            "@VirginAmerica check out new music http://t.co/maRcnOCWzn\n",
            "@virginamerica how's a direct flight FLL-&gt;SFO have unexpected layover in Vegas 4 fuel yet peeps next to me bought for Vegas flight. #sneaky\n",
            "@VirginAmerica your no Late Flight bag check just lost you my business. I missed flight and AM apt. Three other people on flight had same exp.\n",
            "@VirginAmerica - amazing customer  service, again! 游눗游눗 RaeAnn in SF - she's the best! #customerservice #virginamerica #flying\n",
            "@VirginAmerica called your service line and was hung up on. This is awesome. #sarcasm\n",
            "@VirginAmerica your site is tripping. I'm trying to check in and I'm getting the plain text version. I am reluctant to enter any card info.\n",
            "@VirginAmerica I was scheduled for SFO 2 DAL flight 714 today. Changed to 24th due weather. Looks like flight still on?\n",
            "@VirginAmerica has getaway deals through May, from $59 one-way. Lots of cool cities http://t.co/tZZJhuIbCH #CheapFlights #FareCompare\n",
            "@VirginAmerica has getaway deals through May, from $59 one-way. Lots of cool cities http://t.co/RPdBpX3wNd #CheapFlights #FareCompare\n",
            "@VirginAmerica has getaway deals through May, from $59 one-way. Lots of cool cities http://t.co/B2Xi4YG5T8 #CheapFlights #FareCompare\n",
            "@VirginAmerica has getaway deals through May, from $59 one-way. Lots of cool cities http://t.co/QDlJHslOI5 #CheapFlights #FareCompare\n",
            "@VirginAmerica Have a great week 游뤽랟\n",
            "@VirginAmerica come back to #PHL already. We need you to take us out of this horrible cold. #pleasecomeback http://t.co/gLXFwP6nQH\n",
            "@VirginAmerica should I be concerned that I am about to fly on a plane that needs to be delayed due to a \"tech stop\"?\n",
            "@VirginAmerica is the best airline I have flown on.Easy to change your reservation,helpful representatives &amp; a comfortable flying experience\n",
            "@VirginAmerica and again! Another rep kicked butt! Naelah represents your team so beautifully!! Thank you!!!\n",
            "@VirginAmerica your beautiful front-end design is down right now; but it was cool to still book my ticket b/c all your back-end was secure.\n",
            "@VirginAmerica Love the team running Gate E9 at LAS tonight. Waited for a delayed flight, and they kept things entertaining\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Crear un vectorizador para contar las palabras en los textos\n",
        "vectorizador = CountVectorizer()\n",
        "\n",
        "# Aplicar el vectorizador a todo el conjunto de datos\n",
        "X = vectorizador.fit_transform(df['text'])\n",
        "\n",
        "# Obtener las palabras m치s frecuentes en cada clase\n",
        "palabras_positivas = pd.DataFrame(X[df['airline_sentiment'] == 'positive'].toarray(), columns=vectorizador.get_feature_names_out()).sum(axis=0)\n",
        "palabras_negativas = pd.DataFrame(X[df['airline_sentiment'] == 'negative'].toarray(), columns=vectorizador.get_feature_names_out()).sum(axis=0)\n",
        "\n",
        "# Crear DataFrames para las palabras m치s frecuentes en cada clase\n",
        "palabras_positivas_contador = pd.DataFrame({'Palabra': palabras_positivas.index, 'Conteo': palabras_positivas.values})\n",
        "palabras_negativas_contador = pd.DataFrame({'Palabra': palabras_negativas.index, 'Conteo': palabras_negativas.values})\n",
        "\n",
        "# Ordenar los DataFrames por conteo en orden descendente\n",
        "palabras_positivas_contador = palabras_positivas_contador.sort_values(by='Conteo', ascending=False)\n",
        "palabras_negativas_contador = palabras_negativas_contador.sort_values(by='Conteo', ascending=False)\n",
        "\n",
        "# Imprimir las palabras m치s frecuentes en cada clase\n",
        "print(\"Palabras m치s frecuentes en tweets positivos:\")\n",
        "print(palabras_positivas_contador.head(10))\n",
        "\n",
        "print(\"\\nPalabras m치s frecuentes en tweets negativos:\")\n",
        "print(palabras_negativas_contador.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sza9sBcvHNWe",
        "outputId": "8e1580f7-0326-498f-8b31-04f332f31e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras m치s frecuentes en tweets positivos:\n",
            "            Palabra  Conteo\n",
            "13120           the     972\n",
            "13326            to     938\n",
            "14944           you     913\n",
            "6157            for     670\n",
            "13103        thanks     611\n",
            "7804        jetblue     595\n",
            "12372  southwestair     576\n",
            "13914        united     528\n",
            "13095         thank     455\n",
            "2281            and     451\n",
            "\n",
            "Palabras m치s frecuentes en tweets negativos:\n",
            "         Palabra  Conteo\n",
            "13326         to    6048\n",
            "13120        the    4114\n",
            "6004      flight    2943\n",
            "13914     united    2899\n",
            "2281         and    2825\n",
            "9815          on    2792\n",
            "14944        you    2722\n",
            "6157         for    2714\n",
            "9248          my    2407\n",
            "14086  usairways    2375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Calcular el tercer cuartil de las frecuencias\n",
        "percentil_positivo = np.percentile(palabras_positivas_contador['Conteo'], 99.5)\n",
        "percentil_negativo = np.percentile(palabras_negativas_contador['Conteo'], 99.5)\n",
        "\n",
        "# Identificar palabras comunes dentro del tercer cuartil\n",
        "palabras_comunes_tercer_cuartil = set(palabras_positivas_contador[palabras_positivas_contador['Conteo'] >= percentil_positivo]['Palabra']).intersection(\n",
        "    set(palabras_negativas_contador[palabras_negativas_contador['Conteo'] >= percentil_negativo]['Palabra']))\n",
        "\n",
        "# Eliminar palabras comunes dentro del tercer cuartil\n",
        "palabras_eliminar = [palabra for palabra in palabras_comunes_tercer_cuartil if\n",
        "                     palabra in palabras_positivas_contador['Palabra'].values and\n",
        "                     palabra in palabras_negativas_contador['Palabra'].values]\n",
        "\n",
        "# Eliminar las palabras comunes\n",
        "palabras_positivas_contador = palabras_positivas_contador[~palabras_positivas_contador['Palabra'].isin(palabras_eliminar)]\n",
        "palabras_negativas_contador = palabras_negativas_contador[~palabras_negativas_contador['Palabra'].isin(palabras_eliminar)]\n",
        "\n",
        "# Imprimir las palabras m치s frecuentes en cada clase despu칠s de eliminar las comunes\n",
        "print(\"Palabras m치s frecuentes en tweets positivos:\")\n",
        "print(palabras_positivas_contador.head(10))\n",
        "\n",
        "print(\"\\nPalabras m치s frecuentes en tweets negativos:\")\n",
        "print(palabras_negativas_contador.head(10))\n",
        "\n",
        "# Imprimir las palabras eliminadas\n",
        "print(\"\\nPalabras eliminadas en ambas clases dentro del tercer cuartil:\")\n",
        "print(palabras_eliminar)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YcXWXXcPLZx",
        "outputId": "d093dfed-0905-4877-9614-320514a6797b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras m치s frecuentes en tweets positivos:\n",
            "             Palabra  Conteo\n",
            "13103         thanks     611\n",
            "13095          thank     455\n",
            "6656           great     236\n",
            "14273  virginamerica     156\n",
            "8532            love     136\n",
            "6750            guys     110\n",
            "6586            good     109\n",
            "9209            much     109\n",
            "2961            best     105\n",
            "6610             got     100\n",
            "\n",
            "Palabras m치s frecuentes en tweets negativos:\n",
            "         Palabra  Conteo\n",
            "3495   cancelled     926\n",
            "2906        been     774\n",
            "7158       hours     649\n",
            "7051        hold     614\n",
            "14551       what     588\n",
            "10378      plane     532\n",
            "14609        why     525\n",
            "4666     delayed     508\n",
            "12586      still     492\n",
            "14570       when     473\n",
            "\n",
            "Palabras eliminadas en ambas clases dentro del tercer cuartil:\n",
            "['it', 'that', 'to', 'was', 'from', 'us', 'now', 'but', 'do', 'and', 'no', 'we', 'be', 'amp', 'out', 'with', 'time', 'is', 'me', 'for', 'at', 'not', 'so', 'this', 'our', 'all', 'gate', 'can', 'americanair', 'united', 'my', 'usairways', 'of', 'co', 'service', 'on', 'jetblue', 'are', 'flight', 'just', 'southwestair', 'have', 'you', 'an', 'the', 'http', 'help', 'customer', 'get', 'up', 'will', 'in', 'your', 'they']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqu칤 repito lo mismo pero con traintestsplit:"
      ],
      "metadata": {
        "id": "jhXuaOWmT0gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Supongamos que tu DataFrame se llama df y tiene las columnas 'texto' y 'sentimiento_aerolinea'\n",
        "\n",
        "# Divisi칩n en datos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['airline_sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un vectorizador para contar las palabras en los textos\n",
        "vectorizador = CountVectorizer()\n",
        "\n",
        "# Aplicar el vectorizador a los datos de entrenamiento y prueba\n",
        "X_train_vectorizado = vectorizador.fit_transform(X_train)\n",
        "X_test_vectorizado = vectorizador.transform(X_test)\n",
        "\n",
        "# Obtener las palabras m치s frecuentes en cada clase para los datos de entrenamiento\n",
        "palabras_positivas_train = pd.DataFrame(X_train_vectorizado[y_train == 'positive'].toarray(), columns=vectorizador.get_feature_names_out()).sum(axis=0)\n",
        "palabras_negativas_train = pd.DataFrame(X_train_vectorizado[y_train == 'negative'].toarray(), columns=vectorizador.get_feature_names_out()).sum(axis=0)\n",
        "\n",
        "# Crear DataFrames para las palabras m치s frecuentes en cada clase para los datos de entrenamiento\n",
        "palabras_positivas_contador_train = pd.DataFrame({'Palabra': palabras_positivas_train.index, 'Conteo': palabras_positivas_train.values})\n",
        "palabras_negativas_contador_train = pd.DataFrame({'Palabra': palabras_negativas_train.index, 'Conteo': palabras_negativas_train.values})\n",
        "\n",
        "# Ordenar los DataFrames por conteo en orden descendente para los datos de entrenamiento\n",
        "palabras_positivas_contador_train = palabras_positivas_contador_train.sort_values(by='Conteo', ascending=False)\n",
        "palabras_negativas_contador_train = palabras_negativas_contador_train.sort_values(by='Conteo', ascending=False)\n",
        "\n",
        "# Calcular el tercer cuartil de las frecuencias para los datos de entrenamiento\n",
        "percentil_positivo_train = np.percentile(palabras_positivas_contador_train['Conteo'], 99.5)\n",
        "percentil_negativo_train = np.percentile(palabras_negativas_contador_train['Conteo'], 99.5)\n",
        "\n",
        "# Identificar palabras comunes dentro del tercer cuartil para los datos de entrenamiento\n",
        "palabras_comunes_percentil_train = set(palabras_positivas_contador_train[palabras_positivas_contador_train['Conteo'] >= percentil_positivo_train]['Palabra']).intersection(\n",
        "    set(palabras_negativas_contador_train[palabras_negativas_contador_train['Conteo'] >= percentil_negativo_train]['Palabra']))\n",
        "\n",
        "# Eliminar palabras comunes dentro del tercer cuartil para los datos de entrenamiento\n",
        "palabras_eliminar_train = [palabra for palabra in palabras_comunes_percentil_train if\n",
        "                           palabra in palabras_positivas_contador_train['Palabra'].values and\n",
        "                           palabra in palabras_negativas_contador_train['Palabra'].values]\n",
        "\n",
        "# Eliminar las palabras comunes para los datos de entrenamiento\n",
        "palabras_positivas_contador_train = palabras_positivas_contador_train[~palabras_positivas_contador_train['Palabra'].isin(palabras_eliminar_train)]\n",
        "palabras_negativas_contador_train = palabras_negativas_contador_train[~palabras_negativas_contador_train['Palabra'].isin(palabras_eliminar_train)]\n",
        "\n",
        "# Imprimir las palabras m치s frecuentes en cada clase despu칠s de eliminar las comunes para los datos de entrenamiento\n",
        "print(\"Palabras m치s frecuentes en tweets positivos (entrenamiento):\")\n",
        "print(palabras_positivas_contador_train.head(10))\n",
        "\n",
        "print(\"\\nPalabras m치s frecuentes en tweets negativos (entrenamiento):\")\n",
        "print(palabras_negativas_contador_train.head(10))\n",
        "\n",
        "# Imprimir las palabras eliminadas para los datos de entrenamiento\n",
        "print(\"\\nPalabras eliminadas en ambas clases dentro del tercer cuartil (entrenamiento):\")\n",
        "print(palabras_eliminar_train)\n",
        "\n",
        "# Aplicar el vectorizador a los datos de prueba\n",
        "X_test_vectorizado = vectorizador.transform(X_test)\n",
        "\n",
        "# Obtener las palabras m치s frecuentes en cada clase para los datos de prueba\n",
        "palabras_positivas_test = pd.DataFrame(X_test_vectorizado[y_test == 'positivo'].toarray(), columns=vectorizador.get_feature_names_out()).sum(axis=0)\n",
        "palabras_negativas_test = pd.DataFrame(X_test_vectorizado[y_test == 'negativo'].toarray(), columns=vectorizador.get_feature_names_out()).sum(axis=0)\n",
        "\n",
        "# Crear DataFrames para las palabras m치s frecuentes en cada clase para los datos de prueba\n",
        "palabras_positivas_contador_test = pd.DataFrame({'Palabra': palabras_positivas_test.index, 'Conteo': palabras_positivas_test.values})\n",
        "palabras_negativas_contador_test = pd.DataFrame({'Palabra': palabras_negativas_test.index, 'Conteo': palabras_negativas_test.values})\n",
        "\n",
        "# Ordenar los DataFrames por conteo en orden descendente para los datos de prueba\n",
        "palabras_positivas_contador_test = palabras_positivas_contador_test.sort_values(by='Conteo', ascending=False)\n",
        "palabras_negativas_contador_test = palabras_negativas_contador_test.sort_values(by='Conteo', ascending=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "ctmoJWbmRHfx",
        "outputId": "1db055ee-301b-4b4c-b6f9-34cac723b481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras m치s frecuentes en tweets positivos (entrenamiento):\n",
            "             Palabra  Conteo\n",
            "11592         thanks     487\n",
            "11585          thank     369\n",
            "5838           great     195\n",
            "6310            http     175\n",
            "12610  virginamerica     129\n",
            "7509            love     105\n",
            "5922            guys      89\n",
            "5775            good      85\n",
            "2307         awesome      83\n",
            "8108            much      78\n",
            "\n",
            "Palabras m치s frecuentes en tweets negativos (entrenamiento):\n",
            "         Palabra  Conteo\n",
            "8362          no    1046\n",
            "3034   cancelled     715\n",
            "2507        been     615\n",
            "6284       hours     501\n",
            "6189        hold     484\n",
            "12842       what     465\n",
            "4391          do     441\n",
            "9136       plane     427\n",
            "12892        why     417\n",
            "4075     delayed     396\n",
            "\n",
            "Palabras eliminadas en ambas clases dentro del tercer cuartil (entrenamiento):\n",
            "['it', 'that', 'to', 'was', 'from', 'us', 'now', 'but', 'and', 'we', 'be', 'amp', 'out', 'with', 'time', 'is', 'me', 'for', 'at', 'not', 'so', 'this', 'our', 'all', 'can', 'americanair', 'united', 'my', 'usairways', 'of', 'co', 'service', 'on', 'jetblue', 'are', 'flight', 'just', 'southwestair', 'have', 'you', 'an', 'the', 'help', 'customer', 'get', 'up', 'will', 'in', 'your', 'they']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Supongamos que tienes las listas de palabras positivas y negativas\n",
        "palabras_positivas_seleccionadas = palabras_positivas_contador_train['Palabra'].tolist()\n",
        "palabras_negativas_seleccionadas = palabras_negativas_contador_train['Palabra'].tolist()\n",
        "\n",
        "# Calcula el bonus para cada palabra\n",
        "bonus_positivo = 1\n",
        "bonus_negativo = -1\n",
        "\n",
        "# Asigna puntuaciones a las palabras seg칰n su frecuencia\n",
        "puntuaciones_positivas = {palabra: bonus_positivo * conteo for palabra, conteo in zip(palabras_positivas_contador_train['Palabra'], palabras_positivas_contador_train['Conteo'])}\n",
        "puntuaciones_negativas = {palabra: bonus_negativo * conteo for palabra, conteo in zip(palabras_negativas_contador_train['Palabra'], palabras_negativas_contador_train['Conteo'])}\n",
        "\n",
        "# Combina las puntuaciones de palabras positivas y negativas\n",
        "puntuaciones_totales = {**puntuaciones_positivas, **puntuaciones_negativas}\n",
        "\n",
        "# Crea una funci칩n para calcular la puntuaci칩n total de un tweet\n",
        "def calcular_puntuacion(tweet):\n",
        "    palabras_tweet = tweet.split()\n",
        "    puntuacion_tweet = sum(puntuaciones_totales.get(palabra, 0) for palabra in palabras_tweet)\n",
        "    return puntuacion_tweet\n",
        "\n",
        "# Aplica la funci칩n a cada tweet en los datos de prueba\n",
        "puntuaciones_tweets = X_test.apply(calcular_puntuacion)\n",
        "\n",
        "# Clasifica los tweets como positivos o negativos seg칰n su puntuaci칩n\n",
        "tweets_clasificados = np.where(puntuaciones_tweets >= 0, 'positivo', 'negativo')\n",
        "\n",
        "# Eval칰a la precisi칩n del modelo\n",
        "accuracy_puntuacion = accuracy_score(y_test, tweets_clasificados)\n",
        "print(f\"Precisi칩n del modelo basado en puntuaciones: {accuracy_puntuacion:.2f}\")\n",
        "\n",
        "# Muestra m칠tricas adicionales como matriz de confusi칩n y reporte de clasificaci칩n\n",
        "print(\"\\nMatriz de Confusi칩n:\")\n",
        "print(confusion_matrix(y_test, tweets_clasificados))\n",
        "\n",
        "print(\"\\nReporte de Clasificaci칩n:\")\n",
        "print(classification_report(y_test, tweets_clasificados))\n"
      ],
      "metadata": {
        "id": "fMJWnX13TyGU",
        "outputId": "c5eb53f0-6afc-4b52-f4fb-7bfeff56b4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-5d1387496ffa>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Aplicar el nuevo vectorizador a los datos de entrenamiento y prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mX_train_vectorizado_seleccionado\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizador_seleccionado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mX_test_vectorizado_seleccionado\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizador_seleccionado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 \u001b[0;34m\"Iterable over raw text documents expected, string object received.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             )\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;34m\"\"\"Check if vocabulary is empty or missing (not fitted)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"vocabulary_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Vocabulary not fitted or provided\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_validate_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Duplicate term in vocabulary: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m                 \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Duplicate term in vocabulary: 'no'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usar un clasificador con traintest split que directamente sen entrene con los tuits vectorizados con naive bayes y por otro lado usar el recuento de palabras para hacer una votaci칩n dandole puntos a cada palabra."
      ],
      "metadata": {
        "id": "cCHfNeGGgtP7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nOPhtsz8gsdC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}